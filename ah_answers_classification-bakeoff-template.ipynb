{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Classification Modeling\n",
    "The goal of this week's assessment is to find the model which best predicts whether or not a person will default on their bank loan. In doing so, we want to utilize all of the different tools we have learned over the course: data cleaning, EDA, feature engineering/transformation, feature selection, hyperparameter tuning, and model evaluation. \n",
    "\n",
    "\n",
    "#### Data Set Information:\n",
    "\n",
    "This research aimed at the case of customers default payments in Taiwan and compares the predictive accuracy of probability of default among six data mining methods. From the perspective of risk management, the result of predictive accuracy of the estimated probability of default will be more valuable than the binary result of classification - credible or not credible clients. Because the real probability of default is unknown, this study presented the novel Sorting Smoothing Method to estimate the real probability of default. With the real probability of default as the response variable (Y), and the predictive probability of default as the independent variable (X), the simple linear regression result (Y = A + BX) shows that the forecasting model produced by artificial neural network has the highest coefficient of determination; its regression intercept (A) is close to zero, and regression coefficient (B) to one. Therefore, among the six data mining techniques, artificial neural network is the only one that can accurately estimate the real probability of default. \n",
    "\n",
    "- NT is the abbreviation for New Taiwain. \n",
    "\n",
    "\n",
    "#### Attribute Information:\n",
    "\n",
    "This research employed a binary variable, default payment (Yes = 1, No = 0), as the response variable. This study reviewed the literature and used the following 23 variables as explanatory variables: \n",
    "- X1: Amount of the given credit (NT dollar): it includes both the individual consumer credit and his/her family (supplementary) credit. \n",
    "- X2: Gender (1 = male; 2 = female). \n",
    "- X3: Education (1 = graduate school; 2 = university; 3 = high school; 4 = others). \n",
    "- X4: Marital status (1 = married; 2 = single; 3 = others). \n",
    "- X5: Age (year). \n",
    "- X6 - X11: History of past payment. We tracked the past monthly payment records (from April to September, 2005) as follows: \n",
    "    - X6 = the repayment status in September, 2005; \n",
    "    - X7 = the repayment status in August, 2005; . . .;\n",
    "    - etc...\n",
    "    - X11 = the repayment status in April, 2005. \n",
    "    - The measurement scale for the repayment status is: -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above. \n",
    "- X12-X17: Amount of bill statement (NT dollar). \n",
    "    - X12 = amount of bill statement in September, 2005;\n",
    "    - etc...\n",
    "    - X13 = amount of bill statement in August, 2005; . . .; \n",
    "    - X17 = amount of bill statement in April, 2005. \n",
    "- X18-X23: Amount of previous payment (NT dollar). \n",
    "    - X18 = amount paid in September, 2005; \n",
    "    - X19 = amount paid in August, 2005; . . .;\n",
    "    - etc...\n",
    "    - X23 = amount paid in April, 2005. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "You will fit three different models (KNN, Logistic Regression, and Decision Tree Classifier) to predict credit card defaults and use gridsearch to find the best hyperparameters for those models. Then you will compare the performance of those three models on a test set to find the best one.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process/Expectations\n",
    "\n",
    "- You will be working in pairs for this assessment\n",
    "\n",
    "### Please have ONE notebook and be prepared to explain how you worked in your pair.\n",
    "\n",
    "1. Clean up your data set so that you can perform an EDA. \n",
    "    - This includes handling null values, categorical variables, removing unimportant columns, and removing outliers.\n",
    "2. Perform EDA to identify opportunities to create new features.\n",
    "    - [Great Example of EDA for classification](https://www.kaggle.com/stephaniestallworth/titanic-eda-classification-end-to-end) \n",
    "    - [Using Pairplots with Classification](https://towardsdatascience.com/visualizing-data-with-pair-plots-in-python-f228cf529166)\n",
    "3. Engineer new features. \n",
    "    - Create polynomial and/or interaction features. \n",
    "    - Additionaly, you must also create **at least 2 new features** that are not interactions or polynomial transformations. \n",
    "        - *For example, you can create a new dummy variable that based on the value of a continuous variable (billamount6 >2000) or take the average of some past amounts.*\n",
    "4. Perform some feature selection. \n",
    "    \n",
    "5. You must fit **three** models to your data and tune **at least 1 hyperparameter** per model. \n",
    "6. Using the F-1 Score, evaluate how well your models perform and identify your best model.\n",
    "7. Using information from your EDA process and your model(s) output provide insight as to which borrowers are more likely to deafult\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.options.display.max_columns = 500 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('training_data.csv' , index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "oldnames = list(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#change data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X1',\n",
       " 'X2',\n",
       " 'X3',\n",
       " 'X4',\n",
       " 'X5',\n",
       " 'X6',\n",
       " 'X7',\n",
       " 'X8',\n",
       " 'X9',\n",
       " 'X10',\n",
       " 'X11',\n",
       " 'X12',\n",
       " 'X13',\n",
       " 'X14',\n",
       " 'X15',\n",
       " 'X16',\n",
       " 'X17',\n",
       " 'X18',\n",
       " 'X19',\n",
       " 'X20',\n",
       " 'X21',\n",
       " 'X22',\n",
       " 'X23',\n",
       " 'Y']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oldnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['pay_1' if (name == 'PAY_0') else 'Y' if (name == list(df.loc['ID'])[-1])  else name.lower() for name in list(df.loc['ID'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>limit_bal</th>\n",
       "      <th>sex</th>\n",
       "      <th>education</th>\n",
       "      <th>marriage</th>\n",
       "      <th>age</th>\n",
       "      <th>pay_1</th>\n",
       "      <th>pay_2</th>\n",
       "      <th>pay_3</th>\n",
       "      <th>pay_4</th>\n",
       "      <th>pay_5</th>\n",
       "      <th>pay_6</th>\n",
       "      <th>bill_amt1</th>\n",
       "      <th>bill_amt2</th>\n",
       "      <th>bill_amt3</th>\n",
       "      <th>bill_amt4</th>\n",
       "      <th>bill_amt5</th>\n",
       "      <th>bill_amt6</th>\n",
       "      <th>pay_amt1</th>\n",
       "      <th>pay_amt2</th>\n",
       "      <th>pay_amt3</th>\n",
       "      <th>pay_amt4</th>\n",
       "      <th>pay_amt5</th>\n",
       "      <th>pay_amt6</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28835</th>\n",
       "      <td>220000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>222598</td>\n",
       "      <td>222168</td>\n",
       "      <td>217900</td>\n",
       "      <td>221193</td>\n",
       "      <td>181859</td>\n",
       "      <td>184605</td>\n",
       "      <td>10000</td>\n",
       "      <td>8018</td>\n",
       "      <td>10121</td>\n",
       "      <td>6006</td>\n",
       "      <td>10987</td>\n",
       "      <td>143779</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25329</th>\n",
       "      <td>200000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>326</td>\n",
       "      <td>326</td>\n",
       "      <td>326</td>\n",
       "      <td>326</td>\n",
       "      <td>326</td>\n",
       "      <td>326</td>\n",
       "      <td>326</td>\n",
       "      <td>326</td>\n",
       "      <td>326</td>\n",
       "      <td>326</td>\n",
       "      <td>326</td>\n",
       "      <td>326</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18894</th>\n",
       "      <td>180000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>80000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51372</td>\n",
       "      <td>51872</td>\n",
       "      <td>47593</td>\n",
       "      <td>43882</td>\n",
       "      <td>42256</td>\n",
       "      <td>42527</td>\n",
       "      <td>1853</td>\n",
       "      <td>1700</td>\n",
       "      <td>1522</td>\n",
       "      <td>1548</td>\n",
       "      <td>1488</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6239</th>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8257</td>\n",
       "      <td>7995</td>\n",
       "      <td>4878</td>\n",
       "      <td>5444</td>\n",
       "      <td>2639</td>\n",
       "      <td>2697</td>\n",
       "      <td>2000</td>\n",
       "      <td>1100</td>\n",
       "      <td>600</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      limit_bal sex education marriage age pay_1 pay_2 pay_3 pay_4 pay_5  \\\n",
       "28835    220000   2         1        2  36     0     0     0     0     0   \n",
       "25329    200000   2         3        2  29    -1    -1    -1    -1    -1   \n",
       "18894    180000   2         1        2  27    -2    -2    -2    -2    -2   \n",
       "690       80000   1         2        2  32     0     0     0     0     0   \n",
       "6239      10000   1         2        2  27     0     0     0     0     0   \n",
       "\n",
       "      pay_6 bill_amt1 bill_amt2 bill_amt3 bill_amt4 bill_amt5 bill_amt6  \\\n",
       "28835     0    222598    222168    217900    221193    181859    184605   \n",
       "25329    -1       326       326       326       326       326       326   \n",
       "18894    -2         0         0         0         0         0         0   \n",
       "690       0     51372     51872     47593     43882     42256     42527   \n",
       "6239      0      8257      7995      4878      5444      2639      2697   \n",
       "\n",
       "      pay_amt1 pay_amt2 pay_amt3 pay_amt4 pay_amt5 pay_amt6  Y  \n",
       "28835    10000     8018    10121     6006    10987   143779  1  \n",
       "25329      326      326      326      326      326      326  0  \n",
       "18894        0        0        0        0        0        0  0  \n",
       "690       1853     1700     1522     1548     1488     1500  0  \n",
       "6239      2000     1100      600      300      300     1000  1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['ID'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.applymap(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22499, 24)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X1: Amount of the given credit (NT dollar): it includes both the individual consumer credit and his/her family (supplementary) credit.\n",
    "X2: Gender (1 = male; 2 = female).\n",
    "X3: Education (1 = graduate school; 2 = university; 3 = high school; 4 = others).\n",
    "X4: Marital status (1 = married; 2 = single; 3 = others). 0 is divorced?\n",
    "X5: Age (year).\n",
    "X6 - X11: History of past payment. We tracked the past monthly payment records (from April to September, 2005) as follows: \n",
    "The measurement scale for the repayment status is: -2= no payment due, -1 = pay duly; 0 = paid minimum, 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 2, 4, 6, 5, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.education.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.pay_1.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[df.Y==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#df.Y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.limit_bal.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.limit_bal.plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['billamt_to_limit']=df.bill_amt1/(df.limit_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['billamt1_to_billamt6']=df.bill_amt1/(df.bill_amt6+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['avg_stat']=(df.pay_1+df.pay_2+df.pay_3+df.pay_4+df.pay_5+df.pay_6)/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pay_to_bill']=(df.pay_amt1+df.pay_amt2+df.pay_amt3+df.pay_amt4+df.pay_amt5+df.pay_amt6)/(df.bill_amt1+df.bill_amt2+df.bill_amt3+df.bill_amt4+df.bill_amt5+df.bill_amt6+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['avg_pay']=(df.pay_amt1/(df.bill_amt1+1)+df.pay_amt2/(df.bill_amt2+1)+df.pay_amt3/(df.bill_amt3+1)+df.pay_amt4/(df.bill_amt4+1)+df.pay_amt5/(df.bill_amt5+1)+df.pay_amt6/(df.bill_amt6+1))/6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,6):\n",
    "    df['bill_change_rate'+str(i)]=(df['bill_amt'+str(i)]-df['bill_amt'+str(i+1)])/(df['bill_amt'+str(i+1)]+1)\n",
    "                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rate_aggr'] = sum([(df['bill_change_rate'+str(i)]**2)**0.5 for i in range(1,6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total_bill'] = sum([df['bill_amt'+str(i)] for i in range(1,6)])\n",
    "df['total_paid'] = sum([df['pay_amt'+str(i)] for i in range(1,6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['thirties']= np.where((df.age.values>29) & (df.age.values<40),1,0)\n",
    "df['forties'] = np.where((df.age.values>39) & (df.age.values<50),1,0)\n",
    "df['fifties'] = np.where((df.age.values>49) & (df.age.values<60),1,0)\n",
    "df['sixties'] = np.where((df.age.values>59) & (df.age.values<70),1,0)\n",
    "df['seventies'] = np.where((df.age.values>69) & (df.age.values<80),1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['missed_payment']=np.where((df.pay_1>0)|(df.pay_2>0)|(df.pay_3>0)|(df.pay_4>0)|(df.pay_5>0)|(df.pay_6>0),1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.marriage = np.where(df.marriage==0, 3, df.marriage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.education = np.where((df.education>4)|(df.education==0),4, df.education)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.get_dummies(df, columns=['pay_'+str(i) for i in range(1,7)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "limit_bal              -0.155958\n",
       "sex                    -0.037953\n",
       "education               0.037384\n",
       "marriage               -0.032121\n",
       "age                     0.014586\n",
       "pay_1                   0.324772\n",
       "pay_2                   0.266810\n",
       "pay_3                   0.241575\n",
       "pay_4                   0.219143\n",
       "pay_5                   0.208229\n",
       "pay_6                   0.193485\n",
       "bill_amt1              -0.016858\n",
       "bill_amt2              -0.011762\n",
       "bill_amt3              -0.012578\n",
       "bill_amt4              -0.009667\n",
       "bill_amt5              -0.007187\n",
       "bill_amt6              -0.005506\n",
       "pay_amt1               -0.071469\n",
       "pay_amt2               -0.057635\n",
       "pay_amt3               -0.054053\n",
       "pay_amt4               -0.054540\n",
       "pay_amt5               -0.054176\n",
       "pay_amt6               -0.055296\n",
       "Y                       1.000000\n",
       "billamt_to_limit        0.089255\n",
       "billamt1_to_billamt6   -0.009966\n",
       "avg_stat                0.286357\n",
       "pay_to_bill            -0.007305\n",
       "avg_pay                -0.023866\n",
       "bill_change_rate1      -0.005655\n",
       "bill_change_rate2      -0.007386\n",
       "bill_change_rate3      -0.003124\n",
       "bill_change_rate4      -0.001687\n",
       "bill_change_rate5      -0.007546\n",
       "rate_aggr              -0.014808\n",
       "total_bill             -0.012343\n",
       "total_paid             -0.094513\n",
       "thirties               -0.041529\n",
       "forties                 0.008628\n",
       "fifties                 0.026032\n",
       "sixties                 0.016180\n",
       "seventies               0.004567\n",
       "missed_payment          0.353528\n",
       "Name: Y, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()['Y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data to be used in the models\n",
    "# Create matrix of features\n",
    "X = df.drop('Y', axis = 1) # grabs everything else but 'Survived'\n",
    "\n",
    "\n",
    "# Create target variable\n",
    "y = df['Y'] # y is the column we're trying to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import Lasso, Ridge, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, f1_score, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)  \n",
    "X_test = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE()\n",
    "X_train, y_train = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    13971\n",
       "0    13971\n",
       "Name: Y, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Fitting and Hyperparameter Tuning\n",
    "KNN, Logistic Regression, Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_depth=9, max_features=6)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# creating our parameters to test\n",
    "rand_forest = RandomForestClassifier(n_estimators = 100, criterion = 'gini', max_depth = 9, max_features = 6, class_weight='balanced')\n",
    "rand_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7826620636747219\n",
      "0.5281105990783409\n"
     ]
    }
   ],
   "source": [
    "y_pred = rand_forest.predict(X_train)\n",
    "print(f1_score(y_pred, y_train))\n",
    "y_pred = rand_forest.predict(X_test)\n",
    "print(f1_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7826620636747219\n",
      "0.5281105990783409\n"
     ]
    }
   ],
   "source": [
    "#w/ SMOTE\n",
    "y_pred = rand_forest.predict(X_train)\n",
    "print(f1_score(y_pred, y_train))\n",
    "y_pred = rand_forest.predict(X_test)\n",
    "print(f1_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_forest.oob_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.02702\n",
      "Feature: 1, Score: 0.00249\n",
      "Feature: 2, Score: 0.02260\n",
      "Feature: 3, Score: 0.00766\n",
      "Feature: 4, Score: 0.01027\n",
      "Feature: 5, Score: 0.16762\n",
      "Feature: 6, Score: 0.06362\n",
      "Feature: 7, Score: 0.03921\n",
      "Feature: 8, Score: 0.02643\n",
      "Feature: 9, Score: 0.02849\n",
      "Feature: 10, Score: 0.02080\n",
      "Feature: 11, Score: 0.01529\n",
      "Feature: 12, Score: 0.01168\n",
      "Feature: 13, Score: 0.01053\n",
      "Feature: 14, Score: 0.00945\n",
      "Feature: 15, Score: 0.01073\n",
      "Feature: 16, Score: 0.01063\n",
      "Feature: 17, Score: 0.02091\n",
      "Feature: 18, Score: 0.02212\n",
      "Feature: 19, Score: 0.01504\n",
      "Feature: 20, Score: 0.01371\n",
      "Feature: 21, Score: 0.01394\n",
      "Feature: 22, Score: 0.01833\n",
      "Feature: 23, Score: 0.02442\n",
      "Feature: 24, Score: 0.01316\n",
      "Feature: 25, Score: 0.09857\n",
      "Feature: 26, Score: 0.01796\n",
      "Feature: 27, Score: 0.01090\n",
      "Feature: 28, Score: 0.01314\n",
      "Feature: 29, Score: 0.01378\n",
      "Feature: 30, Score: 0.01277\n",
      "Feature: 31, Score: 0.01169\n",
      "Feature: 32, Score: 0.01150\n",
      "Feature: 33, Score: 0.01478\n",
      "Feature: 34, Score: 0.01554\n",
      "Feature: 35, Score: 0.03890\n",
      "Feature: 36, Score: 0.00125\n",
      "Feature: 37, Score: 0.00114\n",
      "Feature: 38, Score: 0.00051\n",
      "Feature: 39, Score: 0.00037\n",
      "Feature: 40, Score: 0.00014\n",
      "Feature: 41, Score: 0.11092\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pyplot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-e739b51e38a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Feature: %0d, Score: %.5f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# plot feature importance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimportance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimportance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pyplot' is not defined"
     ]
    }
   ],
   "source": [
    "importance=rand_forest.feature_importances_\n",
    "for i,v in enumerate(importance):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(rand_forest.feature_importances_, index =df.drop('Y', axis = 1).columns,  columns=['importance']).sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pay_1</th>\n",
       "      <td>0.167621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missed_payment</th>\n",
       "      <td>0.110918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_stat</th>\n",
       "      <td>0.098574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pay_2</th>\n",
       "      <td>0.063618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pay_3</th>\n",
       "      <td>0.039208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_paid</th>\n",
       "      <td>0.038898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pay_5</th>\n",
       "      <td>0.028491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>limit_bal</th>\n",
       "      <td>0.027025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pay_4</th>\n",
       "      <td>0.026431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>billamt_to_limit</th>\n",
       "      <td>0.024418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>0.022596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pay_amt2</th>\n",
       "      <td>0.022119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pay_amt1</th>\n",
       "      <td>0.020910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pay_6</th>\n",
       "      <td>0.020803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pay_amt6</th>\n",
       "      <td>0.018332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pay_to_bill</th>\n",
       "      <td>0.017961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_bill</th>\n",
       "      <td>0.015537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bill_amt1</th>\n",
       "      <td>0.015292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pay_amt3</th>\n",
       "      <td>0.015041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rate_aggr</th>\n",
       "      <td>0.014778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pay_amt5</th>\n",
       "      <td>0.013936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bill_change_rate2</th>\n",
       "      <td>0.013782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pay_amt4</th>\n",
       "      <td>0.013707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>billamt1_to_billamt6</th>\n",
       "      <td>0.013163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bill_change_rate1</th>\n",
       "      <td>0.013137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bill_change_rate3</th>\n",
       "      <td>0.012770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bill_change_rate4</th>\n",
       "      <td>0.011692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bill_amt2</th>\n",
       "      <td>0.011677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bill_change_rate5</th>\n",
       "      <td>0.011496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_pay</th>\n",
       "      <td>0.010902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bill_amt5</th>\n",
       "      <td>0.010733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bill_amt6</th>\n",
       "      <td>0.010631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bill_amt3</th>\n",
       "      <td>0.010528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.010273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bill_amt4</th>\n",
       "      <td>0.009449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marriage</th>\n",
       "      <td>0.007656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>0.002485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thirties</th>\n",
       "      <td>0.001252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forties</th>\n",
       "      <td>0.001144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fifties</th>\n",
       "      <td>0.000508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sixties</th>\n",
       "      <td>0.000369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seventies</th>\n",
       "      <td>0.000140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      importance\n",
       "pay_1                   0.167621\n",
       "missed_payment          0.110918\n",
       "avg_stat                0.098574\n",
       "pay_2                   0.063618\n",
       "pay_3                   0.039208\n",
       "total_paid              0.038898\n",
       "pay_5                   0.028491\n",
       "limit_bal               0.027025\n",
       "pay_4                   0.026431\n",
       "billamt_to_limit        0.024418\n",
       "education               0.022596\n",
       "pay_amt2                0.022119\n",
       "pay_amt1                0.020910\n",
       "pay_6                   0.020803\n",
       "pay_amt6                0.018332\n",
       "pay_to_bill             0.017961\n",
       "total_bill              0.015537\n",
       "bill_amt1               0.015292\n",
       "pay_amt3                0.015041\n",
       "rate_aggr               0.014778\n",
       "pay_amt5                0.013936\n",
       "bill_change_rate2       0.013782\n",
       "pay_amt4                0.013707\n",
       "billamt1_to_billamt6    0.013163\n",
       "bill_change_rate1       0.013137\n",
       "bill_change_rate3       0.012770\n",
       "bill_change_rate4       0.011692\n",
       "bill_amt2               0.011677\n",
       "bill_change_rate5       0.011496\n",
       "avg_pay                 0.010902\n",
       "bill_amt5               0.010733\n",
       "bill_amt6               0.010631\n",
       "bill_amt3               0.010528\n",
       "age                     0.010273\n",
       "bill_amt4               0.009449\n",
       "marriage                0.007656\n",
       "sex                     0.002485\n",
       "thirties                0.001252\n",
       "forties                 0.001144\n",
       "fifties                 0.000508\n",
       "sixties                 0.000369\n",
       "seventies               0.000140"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pickle_path = 'rfc_model.pk1'\n",
    "\n",
    "model_pickle = open(model_pickle_path, 'wb')\n",
    "pickle.dump(rand_forest,model_pickle)\n",
    "model_pickle.close()\n",
    "model_pickle_path = 'rfc_scaler.pk1'\n",
    "\n",
    "model_pickle = open(model_pickle_path, 'wb')\n",
    "pickle.dump(scaler,model_pickle)\n",
    "model_pickle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "k_range = list(range(1, 32, 2))\n",
    "k_scores=[]\n",
    "\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    \n",
    "    f1 = metrics.f1_score(y_test, y_pred)\n",
    "    \n",
    "    k_scores.append(f1)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(zip(k_range, k_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn = KNeighborsClassifier(n_neighbors=31)\n",
    "#knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred=knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acc = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "logreg = LogisticRegression(class_weight='balanced', C=0.8, n_jobs=-1)\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "f1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "logreg.coef_\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "dtc= DecisionTreeClassifier(criterion='entropy')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "dtc = DecisionTreeClassifier(max_depth=6)\n",
    "\n",
    "dtc.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "y_pred_train = dtc.predict(X_train)\n",
    "\n",
    "y_pred_test = dtc.predict(X_test)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Training F1 Score:\", f1_score(y_train, y_pred_train))\n",
    "print(\"Testing F1 Score:\", f1_score(y_test, y_pred_test))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "param_grid = { \n",
    "    'n_estimators': [100,300,500,700,1000],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': list(range(2,10)),\n",
    "    'max_features': list(range(3,7))\n",
    "}\n",
    "grid_tree=GridSearchCV(RandomForestClassifier(), param_grid, cv=5, scoring='f1', verbose=1, n_jobs=-1)\n",
    "grid_tree.fit(X_train, y_train)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "print(grid_tree.best_score_)\n",
    "print(grid_tree.best_params_)\n",
    "print(grid_tree.best_estimator_)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "y_pred = grid_tree.best_estimator_.predict(X_test)\n",
    "\n",
    "# Model F1, how often is the classifier correct?\n",
    "print(\"F1:\", f1_score(y_test, y_pred))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "clf_xgb = xgb.XGBClassifier(objective = 'binary:logistic')\n",
    "param_dist = {'n_estimators': [100,300,500],\n",
    "              'learning_rate': [0.1,0.07,0.05,0.03,0.01],\n",
    "              'max_depth': list(range(3,14,2)),\n",
    "              'colsample_bytree': [0.5,0.45,0.4],\n",
    "              'min_child_weight': [1, 2, 3]\n",
    "             }\n",
    "gsearch1 = GridSearchCV(\n",
    "    estimator = clf_xgb,\n",
    "    param_grid = param_dist, \n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    iid=False, \n",
    "    cv=5)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "gsearch1.fit(X_train, y_train)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'min_child_weight': 1, 'n_estimators': 500}\n",
      "0.8506878300390399\n",
      "Accuracy: 0.813556\n",
      "F1: 0.506180\n"
     ]
    }
   ],
   "source": [
    "print(gsearch1.best_params_)\n",
    "print(gsearch1.best_score_)\n",
    "preds = gsearch1.best_estimator_.predict(X_test)\n",
    "\n",
    "\n",
    "test_f1 = f1_score(y_test, preds)\n",
    "test_acc = accuracy_score(y_test, preds)\n",
    "\n",
    "print(\"Accuracy: %f\" % (test_acc))\n",
    "print(\"F1: %f\" % (test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-7faa61b6c8ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'binary:logistic'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolsample_bytree\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_child_weight\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mx_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    832\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    210\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1159\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[1;32m   1160\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1162\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "x_model = xgb.XGBClassifier(objective = 'binary:logistic', colsample_bytree= 0.5, learning_rate= 0.01, max_depth= 15, min_child_weight= 1, n_estimators= 500)\n",
    "x_model.fit(X_train, y_train)\n",
    "preds= x_model.predict(X_test)\n",
    "\n",
    "test_f1 = f1_score(y_test, preds)\n",
    "test_acc = accuracy_score(y_test, preds)\n",
    "\n",
    "print(\"Accuracy: %f\" % (test_acc))\n",
    "print(\"F1: %f\" % (test_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
